{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aea322b",
   "metadata": {},
   "source": [
    "### Lab 1 - Generative AI Use Case: Summarize Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e49f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b560b8",
   "metadata": {},
   "source": [
    "##### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9807a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 examples from the dataset:\n",
      "example 1: {'id': 'test_0_1', 'dialogue': \"#Person1#: Ms. Dawson, I need you to take a dictation for me.\\n#Person2#: Yes, sir...\\n#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\\n#Person2#: Yes, sir. Go ahead.\\n#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\\n#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\\n#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\\n#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\\n#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\\n#Person2#: This applies to internal and external communications.\\n#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\\n#Person2#: Is that all?\\n#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\", 'summary': 'Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.', 'topic': 'communication method'}\n",
      "example 2: {'id': 'test_0_2', 'dialogue': \"#Person1#: Ms. Dawson, I need you to take a dictation for me.\\n#Person2#: Yes, sir...\\n#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\\n#Person2#: Yes, sir. Go ahead.\\n#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\\n#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\\n#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\\n#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\\n#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\\n#Person2#: This applies to internal and external communications.\\n#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\\n#Person2#: Is that all?\\n#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\", 'summary': 'In order to prevent employees from wasting time on Instant Message programs, #Person1# decides to terminate the use of those programs and asks Ms. Dawson to send out a memo to all employees by the afternoon.', 'topic': 'company policy'}\n",
      "example 3: {'id': 'test_0_3', 'dialogue': \"#Person1#: Ms. Dawson, I need you to take a dictation for me.\\n#Person2#: Yes, sir...\\n#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\\n#Person2#: Yes, sir. Go ahead.\\n#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\\n#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\\n#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\\n#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\\n#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\\n#Person2#: This applies to internal and external communications.\\n#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\\n#Person2#: Is that all?\\n#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\", 'summary': 'Ms. Dawson takes a dictation for #Person1# about prohibiting the use of Instant Message programs in the office. They argue about its reasonability but #Person1# still insists.', 'topic': 'dictation'}\n",
      "example 4: {'id': 'test_1_1', 'dialogue': \"#Person1#: You're finally here! What took so long?\\n#Person2#: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection.\\n#Person1#: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home.\\n#Person2#: I don't think it can be avoided, to be honest.\\n#Person1#: perhaps it would be better if you started taking public transport system to work.\\n#Person2#: I think it's something that I'll have to consider. The public transport system is pretty good.\\n#Person1#: It would be better for the environment, too.\\n#Person2#: I know. I feel bad about how much my car is adding to the pollution problem in this city.\\n#Person1#: Taking the subway would be a lot less stressful than driving as well.\\n#Person2#: The only problem is that I'm going to really miss having the freedom that you have with a car.\\n#Person1#: Well, when it's nicer outside, you can start biking to work. That will give you just as much freedom as your car usually provides.\\n#Person2#: That's true. I could certainly use the exercise!\\n#Person1#: So, are you going to quit driving to work then?\\n#Person2#: Yes, it's not good for me or for the environment.\", 'summary': '#Person2# arrives late because of traffic jam. #Person1# persuades #Person2# to use public transportations to keep healthy and to protect the environment.', 'topic': 'public transportation'}\n",
      "example 5: {'id': 'test_1_2', 'dialogue': \"#Person1#: You're finally here! What took so long?\\n#Person2#: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection.\\n#Person1#: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home.\\n#Person2#: I don't think it can be avoided, to be honest.\\n#Person1#: perhaps it would be better if you started taking public transport system to work.\\n#Person2#: I think it's something that I'll have to consider. The public transport system is pretty good.\\n#Person1#: It would be better for the environment, too.\\n#Person2#: I know. I feel bad about how much my car is adding to the pollution problem in this city.\\n#Person1#: Taking the subway would be a lot less stressful than driving as well.\\n#Person2#: The only problem is that I'm going to really miss having the freedom that you have with a car.\\n#Person1#: Well, when it's nicer outside, you can start biking to work. That will give you just as much freedom as your car usually provides.\\n#Person2#: That's true. I could certainly use the exercise!\\n#Person1#: So, are you going to quit driving to work then?\\n#Person2#: Yes, it's not good for me or for the environment.\", 'summary': \"#Person2# decides to follow #Person1#'s suggestions on quitting driving to work and will try to use public transportations.\", 'topic': 'transportation'}\n"
     ]
    }
   ],
   "source": [
    "dialog_dataset = load_dataset(\"knkarthick/dialogsum\")\n",
    "\n",
    "#Print first 5 examples\n",
    "print(\"First 5 examples from the dataset:\")\n",
    "for i in range(5):\n",
    "    print(f\"example {i+1}: {dialog_dataset['test'][i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a001e8",
   "metadata": {},
   "source": [
    "#### Lets look at few samples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb8dc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 examples from the dataset:\n",
      "EXAMPLE 7\n",
      " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "INPUT DIALOGUE:\n",
      "#Person1#: Kate, you never believe what's happened.\n",
      "#Person2#: What do you mean?\n",
      "#Person1#: Masha and Hero are getting divorced.\n",
      "#Person2#: You are kidding. What happened?\n",
      "#Person1#: Well, I don't really know, but I heard that they are having a separation for 2 months, and filed for divorce.\n",
      "#Person2#: That's really surprising. I always thought they are well matched. What about the kids? Who get custody?\n",
      "#Person1#: Masha, it seems quiet and makable, no quarrelling about who get the house and stock and then contesting the divorce with other details worked out.\n",
      "#Person2#: That's the change from all the back stepping we usually hear about. Well, I still can't believe it, Masha and Hero, the perfect couple. When would they divorce be final?\n",
      "#Person1#: Early in the New Year I guess.\n",
      " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "BASELINE HUMAN SUMMARY\n",
      "#Person1# tells Kate that Masha and Hero are getting a peaceful divorce. Kate feels surprised and asks about their kids.\n",
      " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "EXAMPLE 103\n",
      " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "INPUT DIALOGUE:\n",
      "#Person1#: Well, I'll see you later, Mrs. Todd. My wife is waiting for me to take her shopping.\n",
      "#Person2#: I understand. There's a lot to get done at weekends, especially when you two work and the children are small.\n",
      "#Person1#: That's right. Jane and I have been talking about visiting you. So when I saw you in the garden, I decided to come over and say hello.\n",
      "#Person2#: I'm glad you did. In fact, I should have called on you first, since you have newly moved here.\n",
      "#Person1#: By the way, do you need anything from the store?\n",
      "#Person2#: No, but thanks for the offer. And thank you for coming over.\n",
      "#Person1#: It's a pleasure.\n",
      " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "BASELINE HUMAN SUMMARY\n",
      "#Person1# comes over to say hello to Mrs. Todd, and will go shopping afterwards.\n",
      " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n"
     ]
    }
   ],
   "source": [
    "dash_line = \"_\".join(' ' for x in range(100))\n",
    "\n",
    "example_indices = [7, 103]\n",
    "\n",
    "#Print first 5 examples\n",
    "print(\"First 5 examples from the dataset:\")\n",
    "for i in example_indices:\n",
    "    print(f\"EXAMPLE {i}\")\n",
    "    print(dash_line)\n",
    "    print('INPUT DIALOGUE:')\n",
    "    print(dialog_dataset['test'][i]['dialogue'])\n",
    "    print(dash_line)\n",
    "    print('BASELINE HUMAN SUMMARY')\n",
    "    print(dialog_dataset['test'][i]['summary'])\n",
    "    print(dash_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3b89541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.float16).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff84e01",
   "metadata": {},
   "source": [
    "#### Summarizing without any prompt engineering \n",
    "NOTE: The GenerationConfig with num_beams reduces the memory overhead and thus runs properly locally, otherwise it crashes silently probably becuase of memory getting overwhelmed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66186a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masha and Hero are getting divorced.\n"
     ]
    }
   ],
   "source": [
    "input_text = dialog_dataset['test'][7]['dialogue']\n",
    "encoded_prompt = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=50,  # Limit generation length\n",
    "    num_beams=1,        # Avoid beam search (less memory)\n",
    "    do_sample=False     # Greedy decoding\n",
    ")\n",
    "\n",
    "outputs = model.generate(\n",
    "    encoded_prompt, \n",
    "    generation_config=generation_config)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67b1fe",
   "metadata": {},
   "source": [
    "#### Summarizing with few shot learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd0af4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogues: \n",
      " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "#Person1#: I don't know how to adjust my life. Would you give me a piece of advice?\n",
      "#Person2#: You look a bit pale, don't you?\n",
      "#Person1#: Yes, I can't sleep well every night.\n",
      "#Person2#: You should get plenty of sleep.\n",
      "#Person1#: I drink a lot of wine.\n",
      "#Person2#: If I were you, I wouldn't drink too much.\n",
      "#Person1#: I often feel so tired.\n",
      "#Person2#: You better do some exercise every morning.\n",
      "#Person1#: I sometimes find the shadow of death in front of me.\n",
      "#Person2#: Why do you worry about your future? You're very young, and you'll make great contribution to the world. I hope you take my advice.\n",
      " _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "Generated Summary: \n",
      "Summary: Tony is unhappy because he made a big mistake.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Use following dialogue and summary examples to summarize the given dialogue with a polite tone.\n",
    "Dialogue: {dialog_dataset['test'][5]['dialogue']}\n",
    "Summary: {dialog_dataset['test'][5]['summary']}\n",
    "\n",
    "Dialogue: {dialog_dataset['test'][11]['dialogue']}\n",
    "Summary: {dialog_dataset['test'][11]['summary']}\n",
    "\n",
    "Now, Summarize given dialogue.\n",
    "Dialogue: {dialog_dataset['test'][37]['dialogue']}\n",
    "\"\"\"\n",
    "encoded_prompt = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=80,  # Limit generation length\n",
    "    num_beams=1,        # Avoid beam search (less memory)\n",
    "    do_sample=False     # Greedy decoding\n",
    ")\n",
    "outputs = model.generate(\n",
    "    encoded_prompt,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "print(\"Dialogues: \")\n",
    "print(dash_line)\n",
    "print(dialog_dataset['test'][43]['dialogue'])\n",
    "print(dash_line)\n",
    "print(\"Generated Summary: \")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c357b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
